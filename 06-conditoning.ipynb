{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee1bdc0",
   "metadata": {},
   "source": [
    "To condition the wavenet on linguistic feature we will need to implment local conditioning to our current implmentation of the residual layer. There are three additions that are needed to achieve a locally conditioned wavenet:\n",
    "- upsampling to make conditioned input the same resolution of waveform\n",
    "- conditoned input\n",
    "- 1x1 conovlution filter for conditioned input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e3854",
   "metadata": {},
   "source": [
    "To achieve this we use the following equation from the paper:\n",
    "\n",
    "z = tanh (Wf,k ∗ x + Vf,k ∗ y) σ (Wg,k ∗ x + Vg,k ∗ y),\n",
    "\n",
    "where Vf,k ∗y is now a 1×1 convolution and y = f (h) where f is an upsampling transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12a908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187fc57",
   "metadata": {},
   "source": [
    "We will first look at how upsampling 1d audio samples work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce65342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1d07b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.arange(1, 21, dtype=torch.float).view(1,1,-1)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f6089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 200])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ConvTranspose1d(1, 1, 10, 10)(sample).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b4e1d",
   "metadata": {},
   "source": [
    "Our previous implmentation of the residual layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e5d0a",
   "metadata": {},
   "source": [
    "```\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, dilation, in_channels=1, residual_channels=32, skip_channels=512):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.filter_dialated_conv = DialatedConv1d(in_channels, residual_channels, dilation)\n",
    "        self.gate_dialted_conv = DialatedConv1d(in_channels, residual_channels, dilation)\n",
    "        self.residual_1x1 = Conv1d1x1(residual_channels, residual_channels)\n",
    "        self.skip_1x1 = Conv1d1x1(residual_channels, skip_channels)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        assert inputs.dim() == 3 # To clip the inputs\n",
    "        filter_out, gate_out = self.filter_dialated_conv(inputs), self.gate_dialted_conv(inputs)\n",
    "        z = self.tanh(filter_out) * self.sigmoid(gate_out)\n",
    "        residual_out, skip_out  = self.residual_1x1(z), self.skip_1x1(z)\n",
    "        clipped_inputs = inputs[:,:, -residual_out.size(2):]\n",
    "        residual_out += clipped_inputs\n",
    "        \n",
    "        return residual_out, skip_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3e7654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DialatedConv1d, Conv1d1x1\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, dilation, residual_channels=32, gate_channels=32, skip_channels=512,\n",
    "                 local_channels=0, global_channels=0):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.dilated_conv = DialatedConv1d(residual_channels, gate_channels, dilation)\n",
    "        \n",
    "        self.local_1x1 = self.global_1x1 = None\n",
    "        if local_channels > 0:\n",
    "            self.local_1x1 = Conv1d1x1(local_channels, gate_channels, bias=False)\n",
    "        \n",
    "        if global_channels > 0:\n",
    "            self.global_1x1 = Conv1d1x1(global_channels, gate_channels, bias=False)\n",
    "        \n",
    "        \n",
    "        self.residual_1x1 = Conv1d1x1(gate_channels, residual_channels)\n",
    "        self.skip_1x1 = Conv1d1x1(gate_channels, skip_channels)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, inputs, global_inputs=None, local_inputs=None):\n",
    "        assert inputs.dim() == 3 # To clip the inputs\n",
    "        conv_out = self.dilated_conv(inputs)\n",
    "        \n",
    "        if global_inputs != None:\n",
    "            print(global_inputs.size(2), inputs.size(2))\n",
    "            assert self.global_1x1 != None and global_inputs.size(2) == conv_out.size(2)\n",
    "            global_out = self.global_1x1(global_inputs)   \n",
    "            conv_out += global_out\n",
    "            \n",
    "        if local_inputs != None:\n",
    "            assert self.local_1x1 != None and local_inputs.size(2) == conv_out.size(2)\n",
    "            local_out = self.local_1x1(local_inputs)\n",
    "            conv_out += local_out\n",
    "        \n",
    "        z = self.tanh(conv_out) * self.sigmoid(conv_out)\n",
    "        residual_out, skip_out  = self.residual_1x1(z), self.skip_1x1(z)\n",
    "        \n",
    "        clipped_inputs = inputs[:,:, -residual_out.size(2):]\n",
    "        residual_out += clipped_inputs\n",
    "        \n",
    "        return residual_out, skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "514d2458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 300])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.randn((1,32,300), dtype=torch.float)\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54bc20f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 296]), torch.Size([1, 512, 296]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_out, skip_out = ResidualLayer(2)(sample_data)\n",
    "residual_out.shape, skip_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f65ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 288]), torch.Size([1, 512, 288]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_out, skip_out = ResidualLayer(4)(residual_out)\n",
    "residual_out.shape, skip_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eda69486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 296])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_input = torch.stack((torch.ones((1, 296)), torch.zeros((1,296))), dim=1)\n",
    "global_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3b41cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 296]), torch.Size([1, 512, 296]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_out, skip_out = ResidualLayer(2,global_channels=2)(sample_data, global_inputs=global_input)\n",
    "residual_out.shape, skip_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402bb57",
   "metadata": {},
   "source": [
    "To make the global conditioning input work we have to calculate the size of tensor before inputting it into the residual layers and same with the local conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b8c161ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6716, -0.0872,  0.5723,  ..., -0.8595, -1.0565, -0.7606],\n",
       "          [ 0.8214, -1.6721, -0.0699,  ..., -1.1350, -0.5650,  0.7269],\n",
       "          [ 1.3577,  0.4841, -0.4716,  ...,  2.6977,  1.1704, -0.9785],\n",
       "          ...,\n",
       "          [-0.0090,  1.2861,  2.2006,  ..., -0.7829,  1.3235,  2.0160],\n",
       "          [-1.0036, -1.4957,  2.0787,  ...,  1.0450,  1.5836,  0.7142],\n",
       "          [-0.3482, -0.8100, -0.9892,  ...,  0.6066, -1.4210,  0.2603]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0880, -0.1583,  0.1551,  ..., -0.1778, -0.1762, -0.1299],\n",
       "          [ 0.1606,  0.3654,  0.2770,  ...,  0.5431, -0.0458,  0.4018],\n",
       "          [ 0.0241, -0.0170,  0.0065,  ..., -0.0360, -0.0750, -0.2279],\n",
       "          ...,\n",
       "          [ 0.2181,  0.1260,  0.1515,  ...,  0.2540,  0.1055,  0.2321],\n",
       "          [-0.0189,  0.0228, -0.0284,  ...,  0.1304, -0.1437, -0.0261],\n",
       "          [ 0.0742,  0.1859,  0.1422,  ...,  0.2148,  0.0565,  0.2827]]],\n",
       "        grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_layer = ResidualLayer(2,global_channels=2, local_channels=2)\n",
    "res_layer(sample_data, global_inputs=global_input, local_inputs=global_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af88cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
