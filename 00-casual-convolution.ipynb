{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d4621602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv1d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cf461941",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv1d(1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e6e1cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor([[1.,2.,3.,4.,5.,6.,7.,8.,9.,10.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a08ad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1897, 1.6000, 2.0103, 2.4206, 2.8308, 3.2411, 3.6514, 4.0617]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2554bc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2716,  0.5025,  0.1794]], grad_fn=<SelectBackward0>),\n",
       " tensor(-0.0818, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, bias = list(conv.parameters())[0][0], list(conv.parameters())[1][0]\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "31d95f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.]) tensor([[1., 2., 3.]]) tensor([[1.1897]], grad_fn=<AddBackward0>)\n",
      "tensor([3.]) tensor([[2., 3., 4.]]) tensor([[1.6000]], grad_fn=<AddBackward0>)\n",
      "tensor([4.]) tensor([[3., 4., 5.]]) tensor([[2.0103]], grad_fn=<AddBackward0>)\n",
      "tensor([5.]) tensor([[4., 5., 6.]]) tensor([[2.4206]], grad_fn=<AddBackward0>)\n",
      "tensor([6.]) tensor([[5., 6., 7.]]) tensor([[2.8308]], grad_fn=<AddBackward0>)\n",
      "tensor([7.]) tensor([[6., 7., 8.]]) tensor([[3.2411]], grad_fn=<AddBackward0>)\n",
      "tensor([8.]) tensor([[7., 8., 9.]]) tensor([[3.6514]], grad_fn=<AddBackward0>)\n",
      "tensor([9.]) tensor([[ 8.,  9., 10.]]) tensor([[4.0617]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "filter_size = weight.shape[1]\n",
    "num_elements = test_tensor.shape[1]\n",
    "\n",
    "# Conv1D\n",
    "for i in range(num_elements - filter_size + 1):\n",
    "    data = test_tensor[:, i:i+filter_size]\n",
    "    activation = data @ weight.T + bias\n",
    "    print(data[:,1], data, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "99ba566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "40506fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  0.,  0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tensor = pad(test_tensor, (2,2))\n",
    "padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f68b14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor([[0., 0., 1.]]) tensor([[0.0976]], grad_fn=<AddBackward0>)\n",
      "tensor(2.) tensor([[0., 1., 2.]]) tensor([[0.7795]], grad_fn=<AddBackward0>)\n",
      "tensor(3.) tensor([[1., 2., 3.]]) tensor([[1.1897]], grad_fn=<AddBackward0>)\n",
      "tensor(4.) tensor([[2., 3., 4.]]) tensor([[1.6000]], grad_fn=<AddBackward0>)\n",
      "tensor(5.) tensor([[3., 4., 5.]]) tensor([[2.0103]], grad_fn=<AddBackward0>)\n",
      "tensor(6.) tensor([[4., 5., 6.]]) tensor([[2.4206]], grad_fn=<AddBackward0>)\n",
      "tensor(7.) tensor([[5., 6., 7.]]) tensor([[2.8308]], grad_fn=<AddBackward0>)\n",
      "tensor(8.) tensor([[6., 7., 8.]]) tensor([[3.2411]], grad_fn=<AddBackward0>)\n",
      "tensor(9.) tensor([[7., 8., 9.]]) tensor([[3.6514]], grad_fn=<AddBackward0>)\n",
      "tensor(10.) tensor([[ 8.,  9., 10.]]) tensor([[4.0617]], grad_fn=<AddBackward0>)\n",
      "tensor(0.) tensor([[ 9., 10.,  0.]]) tensor([[2.4986]], grad_fn=<AddBackward0>)\n",
      "tensor(0.) tensor([[10.,  0.,  0.]]) tensor([[-2.7979]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "filter_size = weight.shape[1]\n",
    "num_elements = padded_tensor.shape[1]\n",
    "\n",
    "# Implementing Casual Conv1D\n",
    "for i in range(num_elements - filter_size + 1):\n",
    "    data = padded_tensor[:, i:i+filter_size]\n",
    "    activation = data @ weight.T + bias\n",
    "    print(data[:,2][0], data, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4594c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([[0., 0., 1.]]) tensor([[0.0976]], grad_fn=<AddBackward0>)\n",
      "tensor([2.]) tensor([[0., 1., 2.]]) tensor([[0.7795]], grad_fn=<AddBackward0>)\n",
      "tensor([3.]) tensor([[1., 2., 3.]]) tensor([[1.1897]], grad_fn=<AddBackward0>)\n",
      "tensor([4.]) tensor([[2., 3., 4.]]) tensor([[1.6000]], grad_fn=<AddBackward0>)\n",
      "tensor([5.]) tensor([[3., 4., 5.]]) tensor([[2.0103]], grad_fn=<AddBackward0>)\n",
      "tensor([6.]) tensor([[4., 5., 6.]]) tensor([[2.4206]], grad_fn=<AddBackward0>)\n",
      "tensor([7.]) tensor([[5., 6., 7.]]) tensor([[2.8308]], grad_fn=<AddBackward0>)\n",
      "tensor([8.]) tensor([[6., 7., 8.]]) tensor([[3.2411]], grad_fn=<AddBackward0>)\n",
      "tensor([9.]) tensor([[7., 8., 9.]]) tensor([[3.6514]], grad_fn=<AddBackward0>)\n",
      "tensor([10.]) tensor([[ 8.,  9., 10.]]) tensor([[4.0617]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Last two elements shouldnt be used\n",
    "for i in range(num_elements - filter_size -1):\n",
    "    data = padded_tensor[:, i:i+filter_size]\n",
    "    activation = data @ weight.T + bias\n",
    "    print(data[:,2], data, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f861d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CasualConv1D(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 bias=True, device=None, dtype=None):\n",
    "        super(CasualConv1D, self).__init__(in_channels, out_channels, kernel_size, padding=kernel_size-1, \n",
    "                                           bias=bias, device=device, dtype=dtype)\n",
    "    def forward(self, inputs):\n",
    "        assert inputs.dim() == 3\n",
    "        activations = super(CasualConv1D, self).forward(inputs)\n",
    "        return activations[:,:,:activations.shape[-1]-self.kernel_size[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5c1a25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "casualconv = CasualConv1D(1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c1ab97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7186, 1.2596, 1.2612, 1.2628, 1.2644, 1.2660, 1.2675, 1.2691,\n",
       "          1.2707]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualconv(test_tensor.view(1,1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a02a4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = list(casualconv.parameters())[0][0], list(casualconv.parameters())[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d7ce53d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([[0., 0., 1.]]) tensor([[0.7186]], grad_fn=<AddBackward0>)\n",
      "tensor([2.]) tensor([[0., 1., 2.]]) tensor([[1.2596]], grad_fn=<AddBackward0>)\n",
      "tensor([3.]) tensor([[1., 2., 3.]]) tensor([[1.2612]], grad_fn=<AddBackward0>)\n",
      "tensor([4.]) tensor([[2., 3., 4.]]) tensor([[1.2628]], grad_fn=<AddBackward0>)\n",
      "tensor([5.]) tensor([[3., 4., 5.]]) tensor([[1.2644]], grad_fn=<AddBackward0>)\n",
      "tensor([6.]) tensor([[4., 5., 6.]]) tensor([[1.2660]], grad_fn=<AddBackward0>)\n",
      "tensor([7.]) tensor([[5., 6., 7.]]) tensor([[1.2675]], grad_fn=<AddBackward0>)\n",
      "tensor([8.]) tensor([[6., 7., 8.]]) tensor([[1.2691]], grad_fn=<AddBackward0>)\n",
      "tensor([9.]) tensor([[7., 8., 9.]]) tensor([[1.2707]], grad_fn=<AddBackward0>)\n",
      "tensor([10.]) tensor([[ 8.,  9., 10.]]) tensor([[1.2723]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# It matches so the implmentation works as expected\n",
    "padded_tensor = pad(test_tensor, (2,2))\n",
    "for i in range(num_elements - filter_size -1):\n",
    "    data = padded_tensor[:, i:i+filter_size]\n",
    "    activation = data @ weight.T + bias\n",
    "    print(data[:,2], data, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca43cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
